import streamlit as st
from langchain_community.document_loaders.csv_loader import CSVLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI
from langchain_chroma import Chroma
from langchain_core.prompts import ChatPromptTemplate
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain.chains import create_retrieval_chain
from dotenv import load_dotenv
import joblib
import os

# 1. Ayarlar ve API AnahtarlarÄ±
st.set_page_config(page_title="MovieBot RAG", layout="wide")
load_dotenv()

st.title("ğŸ¬ AI Destekli Film AsistanÄ±")

# --- 2. Ã–NBELLEKLEME (PERFORMANS Ä°Ã‡Ä°N) ---

@st.cache_resource
def load_intent_model():
    """EÄŸitilmiÅŸ intent sÄ±nÄ±flandÄ±rma modelini yÃ¼kler."""
    model_path = 'models/intent_model.pkl'
    if os.path.exists(model_path):
        return joblib.load(model_path)
    return None

@st.cache_resource
def initialize_vectorstore():
    """Film verisetini yÃ¼kler ve vektÃ¶r veritabanÄ±nÄ± hazÄ±rlar."""
    if not os.path.exists("IMDB_Top_1000_Movies_Dataset.csv"):
        st.error("Veri seti dosyasÄ± (csv) bulunamadÄ±!")
        return None

    loader = CSVLoader("IMDB_Top_1000_Movies_Dataset.csv", encoding='utf-8')
    data = loader.load()

    text_splitter = RecursiveCharacterTextSplitter(chunk_size=4000, chunk_overlap=200)
    docs = text_splitter.split_documents(data)

    embeddings = GoogleGenerativeAIEmbeddings(model="models/text-embedding-004", task_batch_size=100)
    vector_store = Chroma.from_documents(documents=docs, embedding=embeddings)
    
    return vector_store.as_retriever(search_type="similarity", search_kwargs={"k": 5})

# KaynaklarÄ± yÃ¼kle
classifier = load_intent_model()
retriever = initialize_vectorstore()

# --- 3. SABÄ°T GEMINI MODELÄ° TANIMI ---
# Model seÃ§imi kaldÄ±rÄ±ldÄ±, doÄŸrudan Gemini tanÄ±mlanÄ±yor.
llm = ChatGoogleGenerativeAI(
    model="gemini-1.5-flash", # 2.5 henÃ¼z genel kullanÄ±ma aÃ§Ä±k deÄŸil, 1.5 en kararlÄ± sÃ¼rÃ¼m
    temperature=0.3,
    max_tokens=500
)

# --- 4. RAG PROMPT TASARIMI ---
system_prompt = (
    "Sen yardÄ±msever bir film Ã¶neri asistanÄ±sÄ±n. AÅŸaÄŸÄ±daki film veritabanÄ± baÄŸlamÄ±nÄ± (context) kullanarak kullanÄ±cÄ±nÄ±n sorularÄ±nÄ± yanÄ±tla."
    "\n\n"
    "Kurallar:"
    "1. Sadece verilen baÄŸlamdaki (context) filmleri Ã¶ner."
    "2. Ä°lgili yerlerde IMDB puanÄ±, yÄ±l ve oyuncu bilgilerini belirt."
    "3. EÄŸer baÄŸlamda cevap yoksa, dÃ¼rÃ¼stÃ§e 'Veri setimde bu bilgi yok' de."
    "\n\n"
    "Context:\n{context}"
)

prompt_template = ChatPromptTemplate.from_messages(
    [
        ("system", system_prompt),
        ("user", "{input}"),
    ]
)

# --- 5. CHAT ARAYÃœZÃœ VE AKIÅ ---

# Yan MenÃ¼ (Sadece temizleme butonu kaldÄ±)
with st.sidebar:
    st.header("âš™ï¸ Ä°ÅŸlemler")
    if st.button("Sohbeti Temizle"):
        st.session_state.messages = []
        st.rerun()
    
    # Debug: Modelin yÃ¼klÃ¼ olup olmadÄ±ÄŸÄ±nÄ± gÃ¶ster
    if classifier:
        st.success("âœ… Intent Modeli Aktif")
    else:
        st.warning("âš ï¸ Intent Modeli YÃ¼klenemedi")

# Sohbet GeÃ§miÅŸini BaÅŸlat
if "messages" not in st.session_state:
    st.session_state.messages = []

# Eski mesajlarÄ± ekrana bas
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.write(message["content"])

# KULLANICI GÄ°RDÄ°SÄ°
if query := st.chat_input("Film sorun veya sohbet edin..."):
    
    # 1. KullanÄ±cÄ± mesajÄ±nÄ± ekle
    st.session_state.messages.append({"role": "user", "content": query})
    with st.chat_message("user"):
        st.write(query)

    response_text = ""
    intent = "MOVIE_QUERY" # VarsayÄ±lan

    # 2. INTENT (NÄ°YET) TAHMÄ°NÄ°
    if classifier:
        intent = classifier.predict([query])[0]
        # Ä°steÄŸe baÄŸlÄ±: Niyeti debug iÃ§in konsola veya sidebara yazdÄ±rabilirsin
        # print(f"Tahmin edilen niyet: {intent}")

    # 3. NÄ°YETE GÃ–RE CEVAPLAMA MANTIÄI
    with st.chat_message("assistant"):
        
        # A) Sohbet / SelamlaÅŸma (LLM Harcamaz)
        if intent == "GREETING":
            response_text = "Merhaba! Size filmler hakkÄ±nda nasÄ±l yardÄ±mcÄ± olabilirim? ğŸ¬"
            st.write(response_text)
            
        elif intent == "GOODBYE":
            response_text = "GÃ¶rÃ¼ÅŸmek Ã¼zere! Ä°yi seyirler dilerim."
            st.write(response_text)
            
        elif intent == "CHITCHAT":
            response_text = "Ben sadece filmlerden anlayan bir asistanÄ±m. Bana favori tÃ¼rÃ¼nÃ¼ sorabilirsin!"
            st.write(response_text)
            
        elif intent == "REJECT":
            response_text = "AnladÄ±m, baÅŸka bir Ã¶neri ister misin?"
            st.write(response_text)
            
        elif intent == "OTHER":
            response_text = "ÃœzgÃ¼nÃ¼m, siyaset, hava durumu veya yemek tarifleri alanÄ±m dÄ±ÅŸÄ±. Sadece sinema konuÅŸalÄ±m! ğŸ¿"
            st.write(response_text)
            
        # B) Film Sorusu (RAG Devreye Girer)
        else: # MOVIE_QUERY veya TanÄ±msÄ±z
            with st.spinner("VeritabanÄ± taranÄ±yor..."):
                if retriever:
                    question_answering_chain = create_stuff_documents_chain(llm, prompt_template)
                    rag_chain = create_retrieval_chain(retriever, question_answering_chain)
                    
                    response = rag_chain.invoke({"input": query})
                    response_text = response["answer"]
                    st.write(response_text)
                else:
                    response_text = "VeritabanÄ± baÄŸlantÄ±sÄ± kurulamadÄ±."
                    st.error(response_text)

    # 4. Asistan cevabÄ±nÄ± geÃ§miÅŸe kaydet
    st.session_state.messages.append({"role": "assistant", "content": response_text})